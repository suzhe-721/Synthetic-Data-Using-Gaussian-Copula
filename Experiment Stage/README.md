# Synthetic Data Experiemnt Result

## Introduction
In the introduction sections, we delved into the burgeoning challenges associated with synthetic data
generation, particularly emphasizing the constraints imposed by limited access to real datasets. As
we transition into the experimental phase of this thesis, our primary objective is to rigorously
assess the efficacy of the two models we have implemented: the Gaussian Mixture Copula Model
(GMCM) and the Gaussian Copula KMeans Model (GCKM). The cornerstone of this experimental
investigation is to ascertain whether these models can substantially enhance the performance of
machine learning algorithms in comparison to the established Synthetic Data Vault (SDV) model
and Y-data Fabric Regular Synthesizer. Our experiments are meticulously designed to not only test
the modelsâ€™ abilities to generate high-fidelity synthetic data but also to evaluate their impact on the
overall performance of various machine learning models. This section is structured to first outline the
experimental setup, including the datasets used, the metrics for evaluation, and the specific machine
learning models employed. Subsequently, we present a detailed analysis of the results obtained from
these experiments, offering insights into the comparative advantages and potential limitations of
the GMCM and GCKM models versus the SDV and Y-data. Through this empirical examination,
we aim to contribute a nuanced understanding of the role of advanced synthetic data generation
techniques in the broader context of machine learning and data analytics.s

## Table of Contents
- [Introduction](#introduction)
- [Table of Contents](#table-of-contents)
- [Installation](#installation)
- [Usage](#usage)
- [Experiment Setup](#experiment-setup)
- [Results](#results)

## SDV Configuration

### SDV Configuration
The Synthetic Data Vault (SDV) configuration process involved several key steps to ensure accurate and effective synthetic data generation:

#### Metadata Detection
- **Tool Used:** SingleTableMetadata class
- **Purpose:** To automatically detect and extract critical information about the dataset's structure, facilitating a more informed synthesis process.

#### Synthesizer Selection
- **Synthesizer Chosen:** GaussianCopulaSynthesizer
- **Rationale:** This synthesizer was selected for its proficiency in modeling the complex dependencies within the dataset, making it suitable for generating synthetic data that closely mimics the statistical properties of the original data.

#### Synthesizer Fitting
- **Methodology:** Fitting the synthesizer to the dataset using the `fit` method.
- **Important Note:** It is crucial to remember that fitting should only be performed using one cluster to maintain the integrity and accuracy of the model learning process.

#### Synthetic Data Generation
- **Process:** Generation of synthetic data was carried out to match the original dataset in terms of row count.
- **Objective:** This ensures that the synthetic dataset is of a comparable size, facilitating valid analysis and evaluation against the original data.

## Y-data Configuration

### Synthesizer Setup
For the synthesis of data, we utilized the `RegularSynthesizer` from the `ydata_synthetic.synthesizers.regular` module, which facilitates the generation of synthetic datasets through a configurable, model-based approach.

#### Model Selection
- **Model Chosen:** `fast`
- **Reason:** The 'fast' model was selected due to its efficiency in generating synthetic data, balancing speed with the quality of the synthesized output.

#### Data Preparation
- **Data Loading:** Data was fetched and prepared for synthesis, ensuring that it is in the correct format for the synthesizing process.
- **Column Specification:**
  - `num_cols`: Specifies the numerical columns in the dataset.
  - `cat_cols`: Specifies the categorical columns in the dataset.

#### Model Fitting
- **Process:** The `fit` method of the `RegularSynthesizer` was employed to train the synthesizer model on the data.
- **Parameters:**
  - `data`: The dataset used for training the synthesizer.
  - `num_cols`: Numerical columns of the dataset.
  - `cat_cols`: Categorical columns of the dataset.

#### Synthetic Data Generation
- **Method:** Utilized the `sample` function of the synthesizer to generate synthetic data.
- **Sample Size:** 1000 rows were generated to create a sufficiently large synthetic dataset for analysis and comparison.

### Synthetic Data Output
The generated synthetic data was then printed out to verify the synthesis process and to inspect the quality and fidelity of the synthetic samples.

```python
synth_data = synth.sample(1000)
print(synth_data)
```

## Experiment Setups

This section outlines the experimental framework used to evaluate the effectiveness of synthetic data generated by the Gaussian Mixture Copula Model (GMCM) and the Gaussian Copula KMeans Model (GCKM). Our evaluation is structured around three methodical approaches:

### Approach 1: Predictive Performance Analysis with Synthetic Data
We assessed the viability of synthetic data by training machine learning models on it and evaluating their performance. The models used were the Random Forest Regressor for the 'Crab Age' dataset and the Gradient Boosting Classifier for the 'Fetal Health' dataset, each chosen for their suitability to the task. Model training was followed by hyperparameter optimization using GridSearchCV and RandomizedSearchCV, respectively. The models' predictive performance was then evaluated on real data using relevant metrics.

### Approach 2: Efficacy of Data Augmentation Using Synthetic Data
This approach tested whether augmenting real datasets with synthetic data improves the predictive accuracy of machine learning models. We augmented the 'Crab Age' and 'Fetal Health' datasets with synthetic data to enhance their robustness and diversity. The augmented datasets were then used to train and evaluate the models, with performance measured against a set of established metrics.

### Approach 3: Evaluating Synthetic Data Fidelity and Coverage
We examined the fidelity of synthetic data by comparing its distributional characteristics with the original data. The Synthetic Data Vault (SDV) scoring system was used to quantitatively assess the synthetic data's quality. Visual comparisons of data distributions and custom metrics like Boundary Adherence and Range Coverage provided a comprehensive evaluation of the synthetic data's authenticity and its ability to replicate the original data's patterns.

This experimental setup aims to understand the utility of synthetic data in enhancing machine learning model performance, particularly in contexts where data privacy, accessibility, or variability are major considerations.

## Results
### Learning Curve Result
- [Learning Curve Result For Crab Age Dataset](All_Model_learning_curve_crab.ipynb)
- [Learning Curve Result For Fetal Health Dataset](All_Model_learning_curve_feta_health.ipynb)
### Data Augmentation Result
- [Data Augmentation For Crab Age](All_Model_Aug_data_compr_crab_age.ipynb)
- [Data Augmentation For Fetal Health](All_Model_Aug_data_compr_feta_health.ipynb)
### Data Fidelity and Coverage
- [Data Fidelity and Coverage Table Summary For All Dataset](Covtype%20and%20MNIST-12/Table_Summary_All_Metrics.ipynb)
  

